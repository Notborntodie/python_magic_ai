
import React, { useRef, useEffect } from 'react';

interface CameraConfig {
  color: string;
  size: number;
  isRunning: boolean;
  poses: Record<string, string>;
}

interface CameraPreviewProps {
  config: CameraConfig;
}

interface Particle {
  x: number;
  y: number;
  vx: number;
  vy: number;
  alpha: number;
  color: string;
}

const CameraPreview: React.FC<CameraPreviewProps> = ({ config }) => {
  const videoRef = useRef<HTMLVideoElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const drawingCanvasRef = useRef<HTMLCanvasElement>(null);
  
  const linesRef = useRef<{points: {x: number, y: number}[], color: string, size: number}[]>([]);
  const currentLineRef = useRef<{points: {x: number, y: number}[], color: string, size: number} | null>(null);
  const particlesRef = useRef<Particle[]>([]);

  useEffect(() => {
    if (!config.isRunning) {
      linesRef.current = [];
      particlesRef.current = [];
      return;
    };

    let active = true;
    const videoElement = videoRef.current!;
    const canvasElement = canvasRef.current!;
    const drawingCanvas = drawingCanvasRef.current!;
    const canvasCtx = canvasElement.getContext('2d')!;
    const drawingCtx = drawingCanvas.getContext('2d')!;

    const hands = new (window as any).Hands({
      locateFile: (file: string) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`
    });

    hands.setOptions({
      maxNumHands: 1,
      modelComplexity: 1,
      minDetectionConfidence: 0.6, // ç¨å¾®é™ä½é˜ˆå€¼ä»¥æé«˜çµæ•åº¦
      minTrackingConfidence: 0.6
    });

    const onResults = (results: any) => {
      if (!active) return;

      if (canvasElement.width !== videoElement.videoWidth) {
        canvasElement.width = videoElement.videoWidth;
        canvasElement.height = videoElement.videoHeight;
        drawingCanvas.width = videoElement.videoWidth;
        drawingCanvas.height = videoElement.videoHeight;
      }

      canvasCtx.save();
      canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
      canvasCtx.translate(canvasElement.width, 0);
      canvasCtx.scale(-1, 1);
      canvasCtx.drawImage(results.image, 0, 0, canvasElement.width, canvasElement.height);

      if (results.multiHandLandmarks && results.multiHandLandmarks.length > 0) {
        const landmarks = results.multiHandLandmarks[0];
        
        // --- é²æ£’æ‰‹åŠ¿æ£€æµ‹ç®—æ³• ---
        // æŒ‡å°–: 8(é£Ÿ), 12(ä¸­), 16(æ— å), 20(å°)
        // æŒ‡æ ¹: 6(é£Ÿ), 10(ä¸­), 14(æ— å), 18(å°)
        const isIndexUp = landmarks[8].y < landmarks[6].y;
        const isMiddleUp = landmarks[12].y < landmarks[10].y;
        const isRingDown = landmarks[16].y > landmarks[14].y;
        const isPinkyDown = landmarks[20].y > landmarks[18].y;

        // åˆ¤å®šé€»è¾‘:
        // ğŸ‘†: åªæœ‰é£ŸæŒ‡ä¼¸å‡º
        const isOneFinger = isIndexUp && !isMiddleUp && isRingDown;
        // âœŒï¸: é£ŸæŒ‡å’Œä¸­æŒ‡éƒ½ä¼¸å‡º
        const isTwoFingers = isIndexUp && isMiddleUp && isRingDown;

        let currentAction = "";
        if (isOneFinger) {
          currentAction = config.poses["ğŸ‘†"] || "";
        } else if (isTwoFingers) {
          currentAction = config.poses["âœŒï¸"] || "";
        }

        // è§†è§‰åé¦ˆï¼šå¦‚æœæ£€æµ‹åˆ°æ‰‹ä½†æ²¡è¯†åˆ«å‡ºåŠ¨ä½œï¼Œæ˜¾ç¤ºåŠé€æ˜ç™½è‰²éª¨æ¶ï¼›è¯†åˆ«å‡ºåŠ¨ä½œï¼Œæ˜¾ç¤ºç”»ç¬”é¢œè‰²ã€‚
        const feedbackColor = currentAction ? config.color : 'rgba(255, 255, 255, 0.4)';
        (window as any).drawConnectors(canvasCtx, landmarks, (window as any).HAND_CONNECTIONS, {
          color: feedbackColor,
          lineWidth: currentAction ? 4 : 2
        });
        (window as any).drawLandmarks(canvasCtx, landmarks, {
          color: feedbackColor,
          radius: (data: any) => data.index === 8 ? 6 : 2
        });

        // é€»è¾‘å¤„ç†
        if (currentAction === "æ¸…é™¤" || currentAction === "ç²’å­çˆ†å‘") {
           explode();
        } else if (currentAction === "ä¹¦å†™") {
           // è½¬æ¢åæ ‡ (é•œåƒ)
           const x = (1 - landmarks[8].x) * drawingCanvas.width;
           const y = landmarks[8].y * drawingCanvas.height;
           
           if (!currentLineRef.current) {
             currentLineRef.current = { points: [], color: config.color, size: config.size };
             linesRef.current.push(currentLineRef.current);
           }
           currentLineRef.current.points.push({ x, y });
        } else {
           currentLineRef.current = null;
        }
      } else {
        currentLineRef.current = null;
      }
      canvasCtx.restore();

      // æ¸²æŸ“ç”»å¸ƒå†…å®¹
      drawingCtx.clearRect(0, 0, drawingCanvas.width, drawingCanvas.height);
      drawingCtx.lineCap = 'round';
      drawingCtx.lineJoin = 'round';
      
      linesRef.current.forEach(line => {
        if (line.points.length < 2) return;
        drawingCtx.beginPath();
        drawingCtx.strokeStyle = line.color;
        drawingCtx.lineWidth = line.size;
        drawingCtx.shadowBlur = 10;
        drawingCtx.shadowColor = line.color;
        drawingCtx.moveTo(line.points[0].x, line.points[0].y);
        for (let i = 1; i < line.points.length; i++) {
          drawingCtx.lineTo(line.points[i].x, line.points[i].y);
        }
        drawingCtx.stroke();
      });

      // æ›´æ–°ç²’å­æ•ˆæœ
      for (let i = particlesRef.current.length - 1; i >= 0; i--) {
        const p = particlesRef.current[i];
        p.x += p.vx; p.y += p.vy; p.alpha -= 0.025;
        if (p.alpha <= 0) { particlesRef.current.splice(i, 1); continue; }
        drawingCtx.fillStyle = p.color;
        drawingCtx.globalAlpha = p.alpha;
        drawingCtx.beginPath();
        drawingCtx.arc(p.x, p.y, Math.random() * 5 + 2, 0, Math.PI * 2);
        drawingCtx.fill();
      }
      drawingCtx.globalAlpha = 1;
    };

    const explode = () => {
      if (linesRef.current.length === 0) return;
      linesRef.current.forEach(line => {
        line.points.forEach((p, i) => {
          if (i % 4 === 0) { // æé«˜ç²’å­å¯†åº¦
            particlesRef.current.push({
              x: p.x, y: p.y,
              vx: (Math.random() - 0.5) * 18,
              vy: (Math.random() - 0.5) * 18,
              alpha: 1, color: line.color
            });
          }
        });
      });
      linesRef.current = [];
    };

    hands.onResults(onResults);
    
    // æ£€æŸ¥æµè§ˆå™¨æ˜¯å¦æ”¯æŒ getUserMedia
    if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
      console.error('æµè§ˆå™¨ä¸æ”¯æŒ getUserMedia');
      alert('æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒæ‘„åƒå¤´è®¿é—®ã€‚\n\nè¯·ç¡®ä¿ï¼š\n1. ä½¿ç”¨ç°ä»£æµè§ˆå™¨ï¼ˆChromeã€Firefoxã€Edgeï¼‰\n2. ä½¿ç”¨ HTTPS æˆ– localhost è®¿é—®\n3. å¦‚æœä½¿ç”¨ IP åœ°å€ï¼Œè¯·åˆ‡æ¢åˆ° HTTPS');
      return;
    }

    let camera: any;
    
    // å…ˆæ‰‹åŠ¨è·å–æ‘„åƒå¤´æµ
    navigator.mediaDevices.getUserMedia({
      video: { 
        width: { ideal: 1280 },
        height: { ideal: 720 },
        facingMode: 'user'
      }
    }).then((mediaStream) => {
      if (!active) {
        mediaStream.getTracks().forEach(track => track.stop());
        return;
      }
      
      stream = mediaStream;
      videoElement.srcObject = mediaStream;
      videoElement.play().catch((e) => {
        console.error('è§†é¢‘æ’­æ”¾å¤±è´¥:', e);
      });

      // ç„¶ååˆ›å»º MediaPipe Camera å·¥å…·
      try {
        camera = new (window as any).Camera(videoElement, {
          onFrame: async () => {
            if (!active) return;
            try { 
              await hands.send({ image: videoElement }); 
            } catch (e) {
              console.warn('Hands processing error:', e);
            }
          },
          width: 1280, 
          height: 720
        });
        
        if (camera && typeof camera.start === 'function') {
          camera.start().catch((error: Error) => {
            console.error('MediaPipe Camera å¯åŠ¨å¤±è´¥:', error);
          });
        }
      } catch (error: any) {
        console.error('åˆ›å»º Camera å¯¹è±¡å¤±è´¥:', error);
        // å¦‚æœ MediaPipe Camera å¤±è´¥ï¼Œå°è¯•æ‰‹åŠ¨å¤„ç†è§†é¢‘æµ
        const processFrame = () => {
          if (!active || videoElement.readyState !== videoElement.HAVE_ENOUGH_DATA) {
            requestAnimationFrame(processFrame);
            return;
          }
          try {
            hands.send({ image: videoElement }).catch((e) => {
              console.warn('Hands send error:', e);
            });
          } catch (e) {
            console.warn('Frame processing error:', e);
          }
          requestAnimationFrame(processFrame);
        };
        processFrame();
      }
    }).catch((error: Error) => {
      console.error('è·å–æ‘„åƒå¤´æƒé™å¤±è´¥:', error);
      alert(`æ‘„åƒå¤´è®¿é—®å¤±è´¥: ${error.message}\n\nå¯èƒ½çš„åŸå› ï¼š\n1. éœ€è¦ä½¿ç”¨ HTTPS æˆ– localhost\n2. éœ€è¦å…è®¸æ‘„åƒå¤´æƒé™\n3. æ‘„åƒå¤´è¢«å…¶ä»–åº”ç”¨å ç”¨\n\nå¦‚æœä½¿ç”¨ IP åœ°å€è®¿é—®ï¼Œè¯·åˆ‡æ¢åˆ° HTTPS æˆ–ä½¿ç”¨ localhost`);
    });

    return () => {
      active = false;
      try {
        // åœæ­¢è§†é¢‘æµ
        if (stream) {
          stream.getTracks().forEach(track => track.stop());
          stream = null;
        }
        if (videoElement.srcObject) {
          videoElement.srcObject = null;
        }
        // åœæ­¢ MediaPipe Camera
        if (camera && typeof camera.stop === 'function') {
          camera.stop();
        }
        // å…³é—­ Hands
        if (hands && typeof hands.close === 'function') {
          hands.close();
        }
      } catch (e) {
        console.warn('æ¸…ç†èµ„æºæ—¶å‡ºé”™:', e);
      }
    };
  }, [config.isRunning, config.color, config.size, JSON.stringify(config.poses)]);

  return (
    <div className="relative w-full h-full">
      <video ref={videoRef} className="hidden" playsInline muted />
      <canvas ref={canvasRef} className="absolute inset-0 w-full h-full object-cover" />
      <canvas ref={drawingCanvasRef} className="absolute inset-0 w-full h-full object-cover pointer-events-none" />
    </div>
  );
};

export default CameraPreview;
